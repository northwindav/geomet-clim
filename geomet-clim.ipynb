{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "45ac56fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd92cb31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spot for user-specified options\n",
    "# This script is built to access only the geomet daily climate data\n",
    "# Site for discovery of climate obs and IDs: https://api.weather.gc.ca/collections/climate-daily/items?limit=10&offset=0&bbox=-180%2C34.84%2C131.89%2C82.41&sortby=-LOCAL_DATE\n",
    "# Queryable parameters: https://api.weather.gc.ca/collections/climate-daily/queryables# \n",
    "\n",
    "# To do: Add a 2nd criterion for streaks, e.g. temperature and humidty. \n",
    "\n",
    "# ------ User-specified options below ------\n",
    "# dt_start/end: String, format=YYYY-MM-DD, enclosed in quotes\n",
    "# clim_ids: Strings ECCC Climate Identifiers, separated by pipe (|) for multiple. Enclosed in quotes\n",
    "# params: List of available parameters to return, separated by '%2C'. LOCAL_DATE is required. \n",
    "# api_limit: Integer. The limit per API request. Max is 10,000 for Geomet daily climate data.\n",
    "dt_start = \"1950-01-01\"\n",
    "dt_end = \"2025-12-29\"\n",
    "clim_ids = \"2101300|2101303|2101415|2101290\"\n",
    "params = \"ID%2CLOCAL_DATE%2CMAX_TEMPERATURE%2CMIN_TEMPERATURE%2CMEAN_TEMPERATURE\" \n",
    "api_limit = 10000\n",
    "# ---- End of user-specified options. Nothing below here should be changed. \n",
    "\n",
    "# Options: From geomet doc page. Put all options here\n",
    "base_url = \"https://api.weather.gc.ca/collections/climate-daily/items\"\n",
    "url_opts = \"\".join([f\"?f=csv&limit={api_limit}\",\n",
    "                    f\"&properties={params}\",\n",
    "                    \"&sortby=LOCAL_DATE\"])\n",
    "clim_id = \"\".join([f\"&CLIMATE_IDENTIFIER={clim_ids}\"])\n",
    "\n",
    "# Calculate number of days requested\n",
    "start = datetime.strptime(dt_start, '%Y-%m-%d')\n",
    "end = datetime.strptime(dt_end, '%Y-%m-%d')\n",
    "total_days = (end - start).days + 1\n",
    "\n",
    "geo_urls = []\n",
    "if total_days <= api_limit:\n",
    "    geo_url = \"\".join([base_url, url_opts, f\"&datetime={dt_start}/{dt_end}\", clim_id])\n",
    "    geo_urls = [geo_url]\n",
    "else:\n",
    "    # Build as many calls as needed in api_limit-sized chunks\n",
    "    current_start = start\n",
    "    while current_start <= end:\n",
    "        chunk_end = min(current_start + timedelta(days=api_limit - 1), end)\n",
    "        dt_string = f\"&datetime={current_start.strftime('%Y-%m-%d')}/{chunk_end.strftime('%Y-%m-%d')}\"\n",
    "        geo_url_chunk = \"\".join([base_url, url_opts, dt_string, clim_id])\n",
    "        geo_urls.append(geo_url_chunk)\n",
    "        current_start = chunk_end + timedelta(days=1)\n",
    "\n",
    "# For backward compatibility, set geo_url to the first one if single\n",
    "if len(geo_urls) == 1:\n",
    "    geo_url = geo_urls[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "40885276",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve data into a pandas df\n",
    "if 'geo_urls' in locals() and len(geo_urls) > 1:\n",
    "    df = pd.concat([pd.read_csv(url) for url in geo_urls], ignore_index=True)\n",
    "else:\n",
    "    df = pd.read_csv(geo_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "207435bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert data types\n",
    "df['LOCAL_DATE'] = pd.to_datetime(df['LOCAL_DATE'])\n",
    "df['ID'] = df['ID'].astype(str)\n",
    "\n",
    "# Replace any non-numeric characters in temperature columns with NA for the purposes of sorting. \n",
    "params_list = params.split('%2C')\n",
    "variable_cols = params_list[params_list.index('LOCAL_DATE') + 1:]\n",
    "df[variable_cols] = df[variable_cols].apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "\n",
    "# Sort and drop duplicates.\n",
    "df = df.sort_values(['LOCAL_DATE','MIN_TEMPERATURE','MAX_TEMPERATURE']).drop_duplicates('LOCAL_DATE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "31b6cec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing dates\n",
    "min_date = df['LOCAL_DATE'].dt.date.min()\n",
    "max_date = df['LOCAL_DATE'].dt.date.max()\n",
    "all_dates = pd.date_range(start=min_date, end=max_date, freq='D')\n",
    "existing_dates = df['LOCAL_DATE'].dt.date\n",
    "missing_dates = all_dates.difference(existing_dates)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a948cd80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Periods where MAX_TEMPERATURE did not exceed -20.0 for 5 or more consecutive days:\n",
      "               start        end  count  missing             type\n",
      "streaknum                                                       \n",
      "673       2004-08-10 2004-10-03     55       55  MAX_TEMPERATURE\n",
      "225       1968-12-27 1969-01-22     27        0  MAX_TEMPERATURE\n",
      "243       1971-01-09 1971-01-31     23        0  MAX_TEMPERATURE\n",
      "263       1972-02-16 1972-03-09     23       22  MAX_TEMPERATURE\n",
      "601       1996-01-08 1996-01-30     23       19  MAX_TEMPERATURE\n",
      "...              ...        ...    ...      ...              ...\n",
      "469       1992-12-27 1992-12-31      5        2  MAX_TEMPERATURE\n",
      "403       1985-02-09 1985-02-13      5        0  MAX_TEMPERATURE\n",
      "653       2001-12-15 2001-12-19      5        0  MAX_TEMPERATURE\n",
      "631       1999-01-05 1999-01-09      5        0  MAX_TEMPERATURE\n",
      "901       2019-01-06 2019-01-10      5        0  MAX_TEMPERATURE\n",
      "\n",
      "[132 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "# Find periods where MAX_TEMPERATURE did not exceed -20.0 for 3 or more consecutive days\n",
    "# First, create a dataframe with all dates filled\n",
    "min_date = df['LOCAL_DATE'].min().date()\n",
    "max_date = df['LOCAL_DATE'].max().date()\n",
    "full_dates = pd.date_range(start=min_date, end=max_date, freq='D')\n",
    "df_full = df.set_index('LOCAL_DATE').reindex(full_dates).rename_axis('LOCAL_DATE').reset_index()\n",
    "\n",
    "# Condition: MAX_TEMPERATURE <= -20.0 or NaN (treat NaN as part of streak)\n",
    "condition = (df_full['MAX_TEMPERATURE'] <= -20.0) | df_full['MAX_TEMPERATURE'].isna()\n",
    "\n",
    "# Identify consecutive streaks\n",
    "df_full['streaknum'] = (condition != condition.shift()).cumsum()\n",
    "\n",
    "# Group by streak and get periods where condition is True for >=3 days\n",
    "streaks = df_full[condition].groupby('streaknum').agg(\n",
    "    start=('LOCAL_DATE', 'min'),\n",
    "    end=('LOCAL_DATE', 'max'),\n",
    "    count=('LOCAL_DATE', 'count'),\n",
    "    missing=('MAX_TEMPERATURE', lambda x: x.isna().sum())\n",
    ")\n",
    "long_streaks_max = streaks[streaks['count'] >= 5].sort_values('count', ascending=False)\n",
    "long_streaks_max['type'] = 'MAX_TEMPERATURE'\n",
    "\n",
    "print(\"Periods where MAX_TEMPERATURE did not exceed -20.0 for 5 or more consecutive days:\")\n",
    "print(long_streaks_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ebf7f8b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Periods where MIN_TEMPERATURE reached at least -30.0 for 5 or more consecutive days:\n",
      "            start        end  count  missing             type\n",
      "streak                                                       \n",
      "815    2004-08-10 2004-10-03     55       55  MIN_TEMPERATURE\n",
      "305    1971-01-09 1971-01-31     23        0  MIN_TEMPERATURE\n",
      "327    1972-02-16 1972-03-09     23       22  MIN_TEMPERATURE\n",
      "857    2007-04-08 2007-04-30     23       23  MIN_TEMPERATURE\n",
      "283    1969-01-06 1969-01-23     18        0  MIN_TEMPERATURE\n",
      "...           ...        ...    ...      ...              ...\n",
      "731    1996-11-20 1996-11-24      5        0  MIN_TEMPERATURE\n",
      "735    1996-12-22 1996-12-26      5        0  MIN_TEMPERATURE\n",
      "1031   2016-12-12 2016-12-16      5        0  MIN_TEMPERATURE\n",
      "1063   2019-01-06 2019-01-10      5        0  MIN_TEMPERATURE\n",
      "1051   2017-12-27 2017-12-31      5        0  MIN_TEMPERATURE\n",
      "\n",
      "[117 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "# Find periods where MIN_TEMPERATURE reached at least -30.0 for 3 or more consecutive days\n",
    "# First, create a dataframe with all dates filled\n",
    "min_date = df['LOCAL_DATE'].min().date()\n",
    "max_date = df['LOCAL_DATE'].max().date()\n",
    "full_dates = pd.date_range(start=min_date, end=max_date, freq='D')\n",
    "df_full = df.set_index('LOCAL_DATE').reindex(full_dates).rename_axis('LOCAL_DATE').reset_index()\n",
    "\n",
    "# Condition: MIN_TEMPERATURE <= -30.0 or NaN (treat NaN as part of streak)\n",
    "condition = (df_full['MIN_TEMPERATURE'] <= -30.0) | df_full['MIN_TEMPERATURE'].isna()\n",
    "\n",
    "# Identify consecutive streaks\n",
    "df_full['streak'] = (condition != condition.shift()).cumsum()\n",
    "\n",
    "# Group by streak and get periods where condition is True for >=3 days\n",
    "streaks = df_full[condition].groupby('streak').agg(\n",
    "    start=('LOCAL_DATE', 'min'),\n",
    "    end=('LOCAL_DATE', 'max'),\n",
    "    count=('LOCAL_DATE', 'count'),\n",
    "    missing=('MIN_TEMPERATURE', lambda x: x.isna().sum())\n",
    ")\n",
    "long_streaks_min = streaks[streaks['count'] >= 5].sort_values('count', ascending=False)\n",
    "long_streaks_min['type'] = 'MIN_TEMPERATURE'\n",
    "\n",
    "print(\"Periods where MIN_TEMPERATURE reached at least -30.0 for 5 or more consecutive days:\")\n",
    "print(long_streaks_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b8e205af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing dates exported to missing_dates.csv\n",
      "Geomet climate data exported to geomet_climate_data.csv\n",
      "Cold streaks data exported to cold_streaks.csv\n"
     ]
    }
   ],
   "source": [
    "# Export the stats and the list of missing data to csv files in the current wd\n",
    "\n",
    "# List of missing dates\n",
    "df_missing = pd.DataFrame({'missing_dates': missing_dates})\n",
    "df_missing.to_csv('missing_dates.csv', index=False)\n",
    "print(\"Missing dates exported to missing_dates.csv\")\n",
    "\n",
    "# df of all sorted data\n",
    "df.to_csv('geomet_climate_data.csv', index=False)\n",
    "print(\"Geomet climate data exported to geomet_climate_data.csv\")\n",
    "\n",
    "# streak dataframes combined\n",
    "all_streaks = pd.concat([long_streaks_max, long_streaks_min], ignore_index=True)\n",
    "all_streaks.to_csv('cold_streaks.csv', index=False)\n",
    "print(\"Cold streaks data exported to cold_streaks.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ecoplug",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
